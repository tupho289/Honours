{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 0. PREPARATION ############################\n",
    "\n",
    "#-------------------------- import packages --------------------------\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_lattice as tfl\n",
    "import tf_keras as keras # need keras 2 to fit Lattice model\n",
    "from tf_keras.models import Sequential, Model\n",
    "from tf_keras.layers import Dense, Input, Multiply, Add, Embedding, Reshape, Concatenate, Dropout, BatchNormalization, Lambda, Layer, CategoryEncoding, Activation\n",
    "from tf_keras.constraints import Constraint\n",
    "from tf_keras.callbacks import EarlyStopping\n",
    "from tf_keras.initializers import Zeros, Constant\n",
    "from tf_keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tf_keras.models import clone_model\n",
    "import keras_tuner as kt\n",
    "from tf_keras import backend as K\n",
    "from tf_keras import regularizers\n",
    "from tf_keras.utils import plot_model\n",
    "from tf_keras.losses import Poisson, Loss\n",
    "from tf_keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from scipy.stats import gamma\n",
    "\n",
    "\n",
    "from pygam import LinearGAM, GAM, s, f, l\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from interpret.glassbox import ExplainableBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- hyperparameters of final model --------------------------\n",
    "imp_interactions = [(\"X3\",\"X4\"),(\"X5\",\"X6\")]\n",
    "inputs = []  # input layers\n",
    "sub_outputs = [] # subnet output\n",
    "num_neurons_main = 40\n",
    "num_layers_main = 5\n",
    "num_neurons_interaction = 100\n",
    "num_layers_interaction = 5\n",
    "activation = 'leaky_relu'\n",
    "lattice_smooth_reg = (0.1,0)\n",
    "num_keypoints = 30\n",
    "monotonicity_list = {\"X3\" : \"decreasing\"}\n",
    "lattice_sizes_full = {}\n",
    "for var in imp_vars:\n",
    "    # for lattice size\n",
    "    if var in cat_vars:\n",
    "        lattice_sizes_full[var] = X_train[var].nunique()\n",
    "    else:\n",
    "        lattice_sizes_full[var] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- model architecture --------------------------\n",
    "# main effect\n",
    "for name in imp_vars:\n",
    "    \n",
    "    # Input layers\n",
    "    input_layer = Input(shape = (1,), name = name)\n",
    "    inputs.append(input_layer)\n",
    "\n",
    "    # subnetworks for main effects\n",
    "    if name in cat_vars: # categorical variables\n",
    "        # categorical variables will be one-hot encoded\n",
    "        embed_layer = Embedding(input_dim = X_train[name].nunique(), \n",
    "                                output_dim = 1, \n",
    "                                name = f\"{name}_embed\")(input_layer)\n",
    "        embed_layer_reshape = Reshape(target_shape = (1,), name = f\"{name}_reshape\")(embed_layer)\n",
    "        cat_output = BatchNormalization(scale = False, name = f\"{name}_dense\")(embed_layer_reshape)\n",
    "        sub_outputs.append(cat_output)\n",
    "    elif name in monotonicity_list: # variables with monotonicity constraint\n",
    "        calibrator_layer = tfl.layers.PWLCalibration(\n",
    "            input_keypoints =  np.linspace(X_train[name].min(), X_train[name].max(), num = num_keypoints), # keypoints\n",
    "            kernel_regularizer = ('hessian', lattice_smooth_reg[0], lattice_smooth_reg[1]), # for smoothness\n",
    "            monotonicity = monotonicity_list[name], # monotonicity constraint\n",
    "            name = f\"{name}_calibrator\"\n",
    "        )(input_layer)\n",
    "        lattice_layer = tfl.layers.Lattice(lattice_sizes = [lattice_sizes_full[name]], \n",
    "                             monotonicities = [\"increasing\"],\n",
    "                             name = f\"{name}_lattice\")(calibrator_layer)\n",
    "        mean_layer = BatchNormalization(scale = False, name = f\"{name}_mean\")(lattice_layer)\n",
    "        sub_outputs.append(mean_layer)\n",
    "    else: # numeric variables\n",
    "        subnet = create_subnet(num_layers_main, num_neurons_main, activation, f\"{name}_subnetwork\")\n",
    "        sub_output = subnet(input_layer)\n",
    "        sub_outputs.append(sub_output)\n",
    "\n",
    "# pairwise interaction effect\n",
    "for (var1, var2) in imp_interactions:\n",
    "    var1_input = inputs[imp_vars.index(var1)]\n",
    "    var2_input = inputs[imp_vars.index(var2)]\n",
    "\n",
    "    if any(var in monotonicity_list for var in [var1, var2]):\n",
    "        lattice_inputs = []\n",
    "\n",
    "        # create calibrator_layer\n",
    "        calibrator_var1 = add_calibrate_layer(var1, X_train, monotonicity_list, lattice_sizes_full, num_keypoints, cat_vars)\n",
    "        calibrator_var2 = add_calibrate_layer(var2, X_train, monotonicity_list, lattice_sizes_full, num_keypoints, cat_vars)\n",
    "        calibrator_layer_var1 = calibrator_var1(var1_input)\n",
    "        calibrator_layer_var2 = calibrator_var2(var2_input)\n",
    "        \n",
    "        # lattice\n",
    "        lattice_inputs.append(calibrator_layer_var1)\n",
    "        lattice_inputs.append(calibrator_layer_var2)\n",
    "        lattice_layer = tfl.layers.Lattice(lattice_sizes = [lattice_sizes_full[var1], lattice_sizes_full[var2]], \n",
    "                             monotonicities = [\"increasing\" if var1 in monotonicity_list else 'none',\n",
    "                                                \"increasing\" if var2 in monotonicity_list else 'none'],\n",
    "                            #  kernel_regularizer = tfl.pwl_calibration_layer.HessianRegularizer(\n",
    "                            #     l1 = 0.01, l2 = 0),\n",
    "                             name = f\"{var1}_{var2}_lattice\")(lattice_inputs)\n",
    "        pairwise_output = BatchNormalization(scale = False, name = f\"{var1}_{var2}_mean\")(lattice_layer)\n",
    "        sub_outputs.append(pairwise_output)\n",
    "    else:\n",
    "        pairwise_input_layer = Concatenate(name = f\"{var1}_{var2}_concat\")([var1_input, var2_input])\n",
    "        pairwise_subnet = create_subnet(num_layers_interaction, \n",
    "                                        num_neurons_interaction, \n",
    "                                        activation, \n",
    "                                        f\"{var1}_{var2}_subnetwork\")\n",
    "        pairwise_dense = pairwise_subnet(pairwise_input_layer)\n",
    "        sub_outputs.append(pairwise_dense)\n",
    "    \n",
    "\n",
    "# combine subnets' outputs\n",
    "subnets = Concatenate(name = \"subnet_output\")(sub_outputs)\n",
    "output_layer = AddSubnetOutput(activation = 'exponential',\n",
    "                     name = \"final_output\")(subnets)\n",
    "\n",
    "# final model\n",
    "model_main_pairwise = Model(inputs = inputs, outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_main_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- add marginal clarity constraint --------------------------\n",
    "lambd = 5\n",
    "for i in range(len(imp_interactions)):\n",
    "    penalty = 0\n",
    "    var1 = imp_interactions[i][0]\n",
    "    var2 = imp_interactions[i][1]\n",
    "    subnet_output = model_main_pairwise.get_layer(\"subnet_output\").output\n",
    "    main_output_var1 = subnet_output[imp_vars.index(var1)]\n",
    "    main_output_var2 = subnet_output[imp_vars.index(var2)]\n",
    "    interaction_output = subnet_output[len(imp_vars) + i]\n",
    "    penalty = lambd * (\n",
    "        K.abs(K.mean(main_output_var1 * interaction_output)) +\n",
    "        K.abs(K.mean(main_output_var2 * interaction_output))\n",
    "    )\n",
    "\n",
    "    # Add the penalty to the model's total loss\n",
    "    model_main_pairwise.add_loss(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- compile and fit --------------------------\n",
    "# remove irrelevant main effects\n",
    "X_train_important = []\n",
    "X_val_important = []\n",
    "X_test_important = []\n",
    "for i in range(len(X_train_split)):\n",
    "    if all_vars[i] in imp_vars:\n",
    "        X_train_important.append(X_train_split[i])\n",
    "        X_val_important.append(X_val_split[i])\n",
    "        X_test_important.append(X_test_split[i])\n",
    "\n",
    "model_main_pairwise.compile(optimizer = \"rmsprop\", loss = gamma_log_likelihood, metrics = [RootMeanSquaredError()])\n",
    "es = EarlyStopping(restore_best_weights = True, patience = 10)\n",
    "%time hist_main_pairwise = model_main_pairwise.fit(X_train_important, y_train, epochs = 5_000, \\\n",
    "    callbacks = [es], batch_size = 1_000, validation_data = (X_val_important, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- quantify variable importance --------------------------\n",
    "subnet_layer = model_main_pairwise.get_layer(\"subnet_output\")\n",
    "subnet_output_model = Model(inputs = model_main_pairwise.inputs, \n",
    "                            outputs = subnet_layer.output)\n",
    "subnet_output_values = subnet_output_model.predict(X_train_important, batch_size = X_train_important[0].shape[0])\n",
    "\n",
    "\n",
    "# Get the variance of each subnetwork across all data points\n",
    "subnet_variance = []\n",
    "for i in range(subnet_output_values.shape[1]):\n",
    "    subnet_variance.append(np.var(subnet_output_values[:, i]))\n",
    "\n",
    "# Define covariates\n",
    "covariates = [name for name in imp_vars]\n",
    "for i in range(len(imp_interactions)):\n",
    "    covariates.append(f\"{imp_interactions[i][0]}_{imp_interactions[i][1]}\")\n",
    "\n",
    "\n",
    "# -------------------------- plot the variable importance --------------------------\n",
    "# Create DataFrame for variable importance\n",
    "var_importance = pd.DataFrame({\"Covariates\": covariates, \"Subnet Variance\": subnet_variance})\n",
    "\n",
    "# Sort the DataFrame by subnet variance in decreasing order\n",
    "varimp_sorted = var_importance.sort_values(by = \"Subnet Variance\", ascending = False)\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(x = \"Covariates\", y = \"Subnet Variance\", data = varimp_sorted)\n",
    "plt.title(\"Subnet Variance by Covariates\")\n",
    "plt.xlabel(\"Covariates\")\n",
    "plt.ylabel(\"Subnet Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Create the Pairwise Only Model --------------------------\n",
    "pairwise_effect = (\"X3\", \"X4\")  # the pairwise effect we want to view\n",
    "pairwise_index = imp_interactions.index(pairwise_effect)\n",
    "subnet_output_layer = model_main_pairwise.get_layer(\"subnet_output\")\n",
    "subnet_model = Model(inputs = model_main_pairwise.inputs, outputs = subnet_output_layer.output)\n",
    "\n",
    "\n",
    "# -------------------------- Generate the Input Grid --------------------------\n",
    "# Create a grid of values\n",
    "grid_length = 100\n",
    "var1_values = np.linspace(X_train[imp_interactions[pairwise_index][0]].min(), \n",
    "                          X_train[imp_interactions[pairwise_index][0]].max(), \n",
    "                          grid_length)\n",
    "var2_values = np.linspace(X_train[imp_interactions[pairwise_index][1]].min(), \n",
    "                          X_train[imp_interactions[pairwise_index][1]].max(), \n",
    "                          grid_length)\n",
    "\n",
    "# Create a meshgrid\n",
    "grid_var1, grid_var2 = np.meshgrid(var1_values, var2_values)\n",
    "\n",
    "# Flatten the grid\n",
    "grid_flat_var1 = grid_var1.ravel()\n",
    "grid_flat_var2 = grid_var2.ravel()\n",
    "\n",
    "\n",
    "# -------------------------- Prepare Inputs for the Model --------------------------\n",
    "grid_inputs = []\n",
    "for var in imp_vars:\n",
    "    if var == imp_interactions[pairwise_index][0]:\n",
    "        grid_inputs.append(grid_flat_var1)\n",
    "    elif var == imp_interactions[pairwise_index][1]:\n",
    "        grid_inputs.append(grid_flat_var2)\n",
    "    else:\n",
    "        grid_inputs.append(np.zeros_like(grid_flat_var1))\n",
    "\n",
    "\n",
    "# -------------------------- Predict Using the Pairwise-Only Model --------------------------\n",
    "# Predict the pairwise interaction effect\n",
    "pairwise_predictions = subnet_model.predict(grid_inputs, batch_size = grid_length**2)[:,len(imp_vars) + pairwise_index]\n",
    "\n",
    "# Reshape the predictions to the grid format\n",
    "heatmap_values = pairwise_predictions.reshape(grid_var1.shape)\n",
    "\n",
    "\n",
    "# -------------------------- Plot the Heatmap --------------------------\n",
    "plt.figure(figsize = (10, 8))\n",
    "contour = plt.contourf(grid_var1, grid_var2, heatmap_values, levels = 10)\n",
    "plt.colorbar(contour)\n",
    "plt.title('Predicted Function by the Model')\n",
    "plt.xlabel(f\"{imp_interactions[pairwise_index][0]}\")\n",
    "plt.ylabel(f\"{imp_interactions[pairwise_index][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------- view the shape function --------------------------\n",
    "# get the prediction\n",
    "subnet_output = subnet_output_model.predict(X_train_important)\n",
    "\n",
    "# create the plot\n",
    "var_name = \"X4\"\n",
    "var_index = imp_vars.index(var_name)\n",
    "plt.figure(figsize = (12, 6))\n",
    "sns.lineplot(x = X_train_important[var_index], \n",
    "             y = subnet_output[:,var_index])\n",
    "plt.xlabel(f\"{var_name}\")\n",
    "plt.ylabel('Subnetwork Output')\n",
    "plt.title(f\"Shape function for {var_name}\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
